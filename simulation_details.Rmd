---
title: "SADM Simulations"
author: "Justin M. Leach"
header-includes:
  - \usepackage{amsmath}
  - \usepackage{bm}
  - \usepackage{hyperref}
  - \hypersetup{colorlinks=true, linkcolor=blue, filecolor=magenta, urlcolor=cyan, citecolor=red}
  - \DeclareMathOperator{\diag}{diag}
output:
  pdf_document:
    number_sections: true
    keep_tex: true
    citation_package: natbib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

This file contains `R` code details regarding simulations in the paper "The Spike-and-Slab Elastic Net as a Classification Tool in Alzheimer's Disease." Simulations and analyses were run on UAB's cluseter. `R` code and scripts for running code on the cluster are in folders "Rcode" and "scripts," respectively. In order to replicate simulations and results, you will need to edit path names and possibly re-write scripts from scratch if your institution does not use slurm workload manager (\url{https://slurm.schedmd.com/overview.html}). 

# What simulation?

Note that we use the UAB cluster to run simulations. We have included the template for reproducing the simulations here, noting what changes are necessary to reproduce the simulations used in the paper. The exact `R` code for each scenario is found in the folder "Rcode." We ultimately include analyses on 2,500 data sets of sample size $N = 250$ using $40 \times 40$ images as predictors to generate binary outcomes as described below. Note that in order to properly reproduce the results, it will be necessary to edit the path names to match your machine.

## Code for simulating data

We will generate the data this using `sim2Dpredictr`. Below is the general code structure used to generate the data. When necessary, we can change the `B.values` argument in `beta_builder()` to assign different parameter sizes (e.g., 0.05). Similarly, unbalanced data was generated by changing the `mu` argument in `sim_Y_MVN_X()`; `mu = 0` results in approximately balanced data sets, `mu = -1` and `mu = -1.25` were used to obtain unbalanced data for $\beta_j = 0.10$ and $\beta_j = 0.05$, respectively. Differing values of `mu` were used to obtain a balance in outcomes similar (but of course not exact) to that in ADNI data.

```{r, message=FALSE}
library(tidyverse)
library(sim2Dpredictr)
library(reshape2)

# colorblind palattes
#palette using grey
cbpg <- c("#999999", "#E69F00", "#56B4E9", "#009E73",
          "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

#palette using black
cbpb <- c("#000000", "#E69F00", "#56B4E9", "#009E73",
          "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

```{r, eval=FALSE}
# simulate data for official analysis

library(tidyverse)
library(sim2Dpredictr)

# load data -> use array jobs
runID <- as.numeric(Sys.getenv("SLURM_ARRAY_TASK_ID"))

# different seed for each job
set.seed(31323 + runID)

# How many simulations?
M <- 500

# How many subjects per dataset?
N <- 250

# Continuous or binary predictors?
x.ms <- "continuous"
# x.ms <- "binary"

# Continuous or binary outcomes?
y.ms <- "binomial"
# y.ms <- "gaussian"

# image resolution; i.e., number of predictors
im.res <- c(40, 40)

if (x.ms == "continuous") {
  # can modify these arguments if needed.
  L = chol_s2Dp(im.res = im.res, rho = 0.90,
                corr.structure = "ar1",
                triangle = "lower")
}

# generate parameter vector
betas <- beta_builder(index.type = "ellipse",
                      w = 8, h = 8,
                      row.index = 15, col.index = 24,
                      B.values = 0.1, im.res = im.res)

# to store data
data.list <- list()

# run simulations
set.seed(23432)
t1 <- proc.time()
for (m in 1:M) {
  
  # generate data
  if (x.ms == "continuous") {
    datm <- sim_Y_MVN_X(N = N, dist = y.ms,
                        mu = -1,
                        L = L$L, S = L$S,
                        B = betas$B)
  } else {
    # from second line on will likely need adjustments
    datm <- sim_Y_Binary_X(N = N, dist = "binomial", B = betas$B, im.res = im.res,
                           lambda = 50, sub.area = TRUE,
                           min.sa = c(0.15, 0.2), max.sa = c(0.25, 0.5),
                           radius.bounds.min.sa = c(0.02, 0.04),
                           radius.bounds.max.sa = c(0.045, 0.06))
  }
  
  data.list[[m]] <- datm
  cat("Simulation ", m, " has completed. \n")
}
proc.time() - t1

# # break up into more manageable pieces; here 10 independent datasets of 500 each.
# D <- 10
# # size of each data set; i.e., 1k in this case.
# S <- M/D
# 
# for (d in 1:D) {
#   min <- 1 + (S * (d - 1))
#   max <- S * d
#   saveRDS(data.list[min:max], 
#           file = paste0("/data/user/jleach/sim_06_2021/simdata/simdata_N500_50x50_", d, ".RDS"))
# }

saveRDS(data.list,
        file = paste0("/data/user/jleach/sim_06_2021/simdata/simdata_N250_40x40_", runID, ".RDS"))
```

## Example subject image

The outcomes are binary, and below we show an example of predictor images. You can simply change `filter(subjectID == 1)` to any number between 1 and 50 to see other example images. 

```{r}

# helps properly display matrices as images
rotate = function(x){
    t(apply(x, 2, rev))
}

# width and height of images is 50 (i.e, 50x50 resolution)
im.wh <- 40

ex.dat <- readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/simdata/simdata_N250_40x40_2.RDS")
ex.dat.smallB <- readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/simdata/simdata_N250_40x40_smallB_2.RDS")

ex.dat.1 <- ex.dat[[1]]
ex.x.1 <- matrix(as.numeric(ex.dat.1 %>% 
                              filter(subjectID == 1) %>% 
                              select(-Y, -subjectID)),
                 nrow = im.wh, ncol = im.wh, byrow = TRUE)

# subjectID = 1
X.1.2D <- rotate(
  matrix(
    ex.x.1, 
    nrow = im.wh, ncol = im.wh, 
    byrow = TRUE
    )
  )


X.1.2D.melt <- melt(
  data.frame(x = 1:im.wh, X.1.2D), 
  id = "x")

```


```{r, fig.width=5, fig.height=5.5}
ggplot(X.1.2D.melt) + 
  geom_raster(aes(x = x, y = variable, fill = value)) +
  labs(fill = "Pixel Value") +
  scale_fill_gradient(low = cbpg[2], high = cbpg[4]) + 
  scale_x_continuous(expand = c(0, 0))+   # get rid of extra space on x-axis
  # guides(fill = FALSE)+                  # turn off color legend
  theme(axis.text = element_blank(),     # turn off the axis annotations
        axis.ticks = element_blank(),
        axis.title = element_blank(),
        legend.position = "bottom")
```

## Balance in outcome

We can check that the balance in the outcomes is what we expect. The cortical thickness data set had 14.29\% with dementia and the tau PET data set had 13.53\% with dementia. On average, we are close to these percentages in both data sets.

```{r}
y.means.ex <- c()

for (i in 1:length(ex.dat)) {
  y.means.ex[i] <- mean(ex.dat[[i]]$Y)
}

# mean(y.means.ex)
# sd(y.means.ex)

y.means.ex.smallB <- c()

for (i in 1:length(ex.dat.smallB)) {
  y.means.ex.smallB[i] <- mean(ex.dat.smallB[[i]]$Y)
}

# mean(y.means.ex.smallB)
# sd(y.means.ex.smallB)

balance.smry <- cbind(
  data.frame(
    Beta = c(0.10, 0.05),
    Mean = c(mean(y.means.ex), mean(y.means.ex.smallB)),
    SD = c(sd(y.means.ex), sd(y.means.ex.smallB))
  ),
  rbind(quantile(y.means.ex, digits = 10),
        quantile(y.means.ex.smallB, digits = 10))
)
knitr::kable(balance.smry,
             caption = "Summaries for Percentage of Events in each Simulation (1st 500 Sims)",
             digits = 10)
```

Given the size of the simulated data, and that it is saved on UAB's cluster, we obtained exact values separately on the cluster and present those here:

```{r}
balance.smry.full <- readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_balance_smry.RDS")

knitr::kable(balance.smry.full,
             caption = "Summaries for Percentage of Events in each Simulation",
             digits = 10)
```

# Analysis details

Of course the difficult part is analyzing the simulated data. We will analyze using traditional models, spike-and-slab models without spatial structure, and spike-and-slab models with spatial structure for the lasso and the elastic net with compromise parameter 0.5, i.e., halfway compromise between ridge and lasso. 

We do not reproduce the files used to run the analyses, but they are found in the folder "Rcode" and easily identified: `glmnet` models run with "rcode_glmnet_N250_40x40.R", `ssnet` models without IAR priors with "rcode_ssnet_N250_40x40.R", and `ssnet` models with IAR priors with "rcode_ssnet_iar_N250_40x40.R".

# Results ($\beta = 0.1$)

## Loading results

Note that while `glmnet` has only one output file, we have to extract and combine results from the `ssnet` models. For now, we extract only inference, not parameter estimates. Remember to change the path names!

```{r}
# load data

# only take 1st 2500 analyses from glmnet models
glmnet.results <- readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_glmnet_N250_40x40.RDS")$inference

ssnet.results <- dplyr::bind_rows(
  readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_ssnet_N250_40x40_500_1.RDS")$inference,
  readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_ssnet_N250_40x40_500_2.RDS")$inference,
  readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_ssnet_N250_40x40_500_3.RDS")$inference,
  readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_ssnet_N250_40x40_500_4.RDS")$inference,
  readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_ssnet_N250_40x40_500_5.RDS")$inference
)
                                  
ssnet.iar.results <- dplyr::bind_rows(
  readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_ssnet_iar_N250_40x40_250_1.RDS")$inference,
  readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_ssnet_iar_N250_40x40_250_2.RDS")$inference,
  readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_ssnet_iar_N250_40x40_250_3.RDS")$inference,
  readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_ssnet_iar_N250_40x40_250_4.RDS")$inference,
  readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_ssnet_iar_N250_40x40_250_5.RDS")$inference,
  readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_ssnet_iar_N250_40x40_250_6.RDS")$inference,
  readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_ssnet_iar_N250_40x40_250_7.RDS")$inference,
  readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_ssnet_iar_N250_40x40_250_8.RDS")$inference,
  readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_ssnet_iar_N250_40x40_250_9.RDS")$inference,
  readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_ssnet_iar_N250_40x40_250_10.RDS")$inference
)

```

## Obtaining optimal models

We need to extract means by elastic net penalty (0.5 or 1), $s_0$, and $s_1$. 

```{r}
glmnet.smry.0 <- glmnet.results %>% 
  select(-model) %>%
  group_by(alpha) %>%
  nest() %>%
  mutate(
    means = map(.x = data, .f = function(x) map_df(x, mean, na.rm = TRUE)),
    sds = map(.x = data, .f = function(x) map_df(x, sd, na.rm = TRUE))
    )

#glmnet.smry.0

glmnet.smry <- glmnet.smry.0 %>% 
  select(-data, -sds) %>%
  unnest(means)

#glmnet.smry

ssnet.smry.0 <- ssnet.results %>%
  select(-model) %>%
  group_by(alpha, s0, s1) %>%
  nest() %>%
  mutate(
    means = map(.x = data, .f = function(x) map_df(x, mean, na.rm = TRUE)),
    sds = map(.x = data, .f = function(x) map_df(x, sd, na.rm = TRUE))
    )

#ssnet.smry.0

ssnet.smry <- ssnet.smry.0 %>%
  select(-data, -sds) %>%
  unnest(means)

#ssnet.smry

ssnet.iar.smry.0 <- ssnet.iar.results %>%
  select(-model) %>%
  group_by(alpha, s0, s1) %>%
  nest() %>%
  mutate(
    means = map(.x = data, .f = function(x) map_df(x, mean, na.rm = TRUE)),
    sds = map(.x = data, .f = function(x) map_df(x, sd, na.rm = TRUE))
    )

#ssnet.iar.smry.0

ssnet.iar.smry <- ssnet.iar.smry.0 %>%
  select(-data, -sds) %>%
  unnest(means)

#ssnet.iar.smry
```

Then we need to select the optimal model parameters for each of the 6 modeling approaches:

```{r}
optimal.ssnet.a05 <- ssnet.smry %>% 
  ungroup() %>%
  filter(alpha == 0.5) %>%
  filter(deviance == min(deviance))

optimal.ssnet.iar.a05 <- ssnet.iar.smry %>%
  ungroup() %>%
  filter(alpha == 0.5) %>%
  filter(deviance == min(deviance))

optimal.ssnet.a1 <- ssnet.smry %>% 
  ungroup() %>%
  filter(alpha == 1) %>%
  filter(deviance == min(deviance))

optimal.ssnet.iar.a1 <- ssnet.iar.smry %>%
  ungroup() %>%
  filter(alpha == 1) %>%
  filter(deviance == min(deviance))

optimal.glmnet <- glmnet.smry %>%
  ungroup()

results.df <- rbind(optimal.glmnet %>% filter(alpha == 1),
                    optimal.ssnet.a1,
                    optimal.ssnet.iar.a1,
                    optimal.glmnet %>% filter(alpha == 0.5),
                    optimal.ssnet.a05,
                    optimal.ssnet.iar.a05)
```

## Tables

```{r}
knitr::kable(cbind(model = c("Lasso", "SSL", "SSL-IAR",
                             "EN", "SSEN", "SSEN-IAR"), 
                   results.df %>% 
                     select(s0, s1, deviance, auc, mse, mae, misclassification)),
             caption = "Prediction Error over 2,500 Simulated Data Sets",
             digits = 4)

knitr::kable(cbind(model = c("Lasso", "SSL", "SSL-IAR",
                             "EN", "SSEN", "SSEN-IAR"), 
                   results.df %>% 
                     select(s0, s1, accuracy, sensitivity, specificity, ppv, npv, mcc, f1)),
             caption = "Results over 2,500 Simulated Data Sets",
             digits = 4)

#for LaTeX
# xtable::xtable(cbind(model = c("Lasso", "SSL", "SSL-IAR",
#                              "EN", "SSEN", "SSEN-IAR"),
#                    results.df %>%
#                      select(s0, s1, deviance, auc, mse, mae, misclassification)),
#                digits = 4)
# xtable::xtable(cbind(model = c("Lasso", "SSL", "SSL-IAR",
#                              "EN", "SSEN", "SSEN-IAR"),
#                    results.df %>%
#                      select(s0, s1, accuracy, sensitivity, specificity, ppv, npv, mcc, f1)),
#                digits = 4)
```

## Figure

```{r}
# wrangle for figures
accuracy.wide <- cbind(Model = c("Lasso", "SSL", "SSL-IAR",
                             "EN", "SSEN", "SSEN-IAR"),
                       results.df %>% select(accuracy, sensitivity, specificity,
                                             ppv, npv, mcc, f1)
)

# number of models in total
nm <- 6
all.long <- cbind(accuracy.wide %>% select(Model),
                  Estimate = c(accuracy.wide$accuracy, 
                               accuracy.wide$sensitivity,
                               accuracy.wide$specificity,
                               accuracy.wide$ppv,
                               accuracy.wide$npv,
                               accuracy.wide$mcc,
                               accuracy.wide$f1),
                  Assessment = c(rep("Accuracy", nm),
                                 rep("Sensitivity", nm),
                                 rep("Specificity", nm),
                                 rep("PPV", nm),
                                 rep("NPV", nm),
                                 rep("MCC", nm),
                                 rep("F1", nm)))
names(all.long) <- c("Model", "Estimate", "Assessment")
all.long$Model <- factor(all.long$Model, 
                         levels = c("Lasso", "SSL", "SSL-IAR",
                                    "EN", "SSEN", "SSEN-IAR"))
all.long$Assessment <- factor(all.long$Assessment,
                              levels = c("Accuracy", "Sensitivity", "Specificity",
                                         "PPV", "NPV", "MCC", "F1"))

ggplot(data = all.long %>% 
         filter(Assessment %in% c("Sensitivity", "Specificity", "PPV", "NPV")),
       mapping = aes(y = Estimate,
                     x = Model, 
                     colour = Assessment,
                     shape = Assessment
                     )
       ) +
  geom_point(size = 3, stroke = 1.5,
             position = position_dodge(width = 0.75)) +
  scale_shape_manual(values = c(15, 17, 18, 25)) +
  scale_color_manual(values = cbpb[c(2, 4, 7, 6)]) +
  # scale_fill_manual(values = cbp.b[c(1, 2, 4, 7, 3 )]) +
  # facet_wrap(~Assessment) +
  scale_x_discrete(name = NULL) +
  scale_y_continuous(limits = c(0.5, 1),
                     breaks = seq(0.5, 1, 0.05)) +
  theme(plot.title = element_text(hjust = 0.5), 
        text = element_text(size = 14),
        legend.position = "bottom")

ggplot(data = all.long %>% 
         filter(Assessment %in% c("Accuracy", "MCC", "F1")),
       mapping = aes(y = Estimate,
                     x = Model, 
                     colour = Assessment,
                     shape = Assessment
                     )
       ) +
  geom_point(size = 3, stroke = 1.5,
             position = position_dodge(width = 0.75)) +
  scale_shape_manual(values = c(8, 4, 14)) +
  scale_color_manual(values = cbpb[c(1, 8, 3)]) +
  # scale_fill_manual(values = cbp.b[c(1, 2, 4, 7, 3 )]) +
  # facet_wrap(~Assessment) +
  scale_x_discrete(name = NULL) +
  scale_y_continuous(limits = c(0.5, 1),
                     breaks = seq(0.5, 1, 0.05)) +
  theme(plot.title = element_text(hjust = 0.5), 
        text = element_text(size = 14),
        legend.position = "bottom")

ggplot(data = all.long,
       mapping = aes(y = Estimate,
                     x = Model, 
                     colour = Assessment,
                     shape = Assessment
                     )
       ) +
  geom_point(size = 3, stroke = 1.5
             #,
             #position = position_dodge(width = 0.75)
             ) +
  scale_shape_manual(values = c(8, 15, 17, 18, 25, 4, 14)) +
  scale_color_manual(values = cbpb[c(8, 2, 4, 7, 6, 1, 3)]) +
  # scale_fill_manual(values = cbp.b[c(1, 2, 4, 7, 3 )]) +
  # facet_wrap(~Assessment) +
  scale_x_discrete(name = NULL) +
  scale_y_continuous(limits = c(0.5, 1),
                     breaks = seq(0.5, 1, 0.05)) +
  theme(plot.title = element_text(hjust = 0.5), 
        text = element_text(size = 14),
        legend.position = "bottom")
```


# Results ($\beta_j = 0.05$)

## Loading results

Note that while `glmnet` has only one output file, we have to extract and combine results from the `ssnet` models. For now, we extract only inference, not parameter estimates.

```{r}
# load data

# only take 1st 2500 analyses from glmnet models
glmnet.results.smallB <- readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_glmnet_N250_40x40_smallB.RDS")$inference

ssnet.results.smallB <- dplyr::bind_rows(
  readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_ssnet_N250_40x40_smallB_500_1.RDS")$inference,
  readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_ssnet_N250_40x40_smallB_500_2.RDS")$inference,
  readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_ssnet_N250_40x40_smallB_500_3.RDS")$inference,
  readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_ssnet_N250_40x40_smallB_500_4.RDS")$inference,
  readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_ssnet_N250_40x40_smallB_500_5.RDS")$inference
)
                                  
ssnet.iar.results.smallB <- dplyr::bind_rows(
  readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_ssnet_iar_N250_40x40_smallB_250_1.RDS")$inference,
  readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_ssnet_iar_N250_40x40_smallB_250_2.RDS")$inference,
  readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_ssnet_iar_N250_40x40_smallB_250_3.RDS")$inference,
  readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_ssnet_iar_N250_40x40_smallB_250_4.RDS")$inference,
  readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_ssnet_iar_N250_40x40_smallB_250_5.RDS")$inference,
  readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_ssnet_iar_N250_40x40_smallB_250_6.RDS")$inference,
  readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_ssnet_iar_N250_40x40_smallB_250_7.RDS")$inference,
  readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_ssnet_iar_N250_40x40_smallB_250_8.RDS")$inference,
  readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_ssnet_iar_N250_40x40_smallB_250_9.RDS")$inference,
  readRDS(file = "C:/Users/cotto/Documents/Publications/paper3/Simulation R Code/results/results_ssnet_iar_N250_40x40_smallB_250_10.RDS")$inference
)

```

## Obtaining optimal models

We need to extract means by elastic net penalty (0.5 or 1), $s_0$, and $s_1$. 

```{r}
glmnet.smry.smallB.0 <- glmnet.results.smallB %>% 
  select(-model) %>%
  group_by(alpha) %>%
  nest() %>%
  mutate(
    means = map(.x = data, .f = function(x) map_df(x, mean, na.rm = TRUE)),
    sds = map(.x = data, .f = function(x) map_df(x, sd, na.rm = TRUE))
    )

#glmnet.smry.smallB.0

glmnet.smry.smallB <- glmnet.smry.smallB.0 %>% 
  select(-data, -sds) %>%
  unnest(means)

#glmnet.smry.smallB

ssnet.smry.smallB.0 <- ssnet.results.smallB %>%
  select(-model) %>%
  group_by(alpha, s0, s1) %>%
  nest() %>%
  mutate(
    means = map(.x = data, .f = function(x) map_df(x, mean, na.rm = TRUE)),
    sds = map(.x = data, .f = function(x) map_df(x, sd, na.rm = TRUE))
    )

#ssnet.smry.smallB.0

ssnet.smry.smallB <- ssnet.smry.smallB.0 %>%
  select(-data, -sds) %>%
  unnest(means)

#ssnet.smry.smallB

ssnet.iar.smry.smallB.0 <- ssnet.iar.results.smallB %>%
  select(-model) %>%
  group_by(alpha, s0, s1) %>%
  nest() %>%
  mutate(
    means = map(.x = data, .f = function(x) map_df(x, mean, na.rm = TRUE)),
    sds = map(.x = data, .f = function(x) map_df(x, sd, na.rm = TRUE))
    )

#ssnet.iar.smry.smallB.0

ssnet.iar.smry.smallB <- ssnet.iar.smry.smallB.0 %>%
  select(-data, -sds) %>%
  unnest(means)

#ssnet.iar.smry.smallB
```

Then we need to select the optimal model parameters for each of the 6 modeling approaches:

```{r}
optimal.ssnet.a05.smallB <- ssnet.smry.smallB %>% 
  ungroup() %>%
  filter(alpha == 0.5) %>%
  filter(deviance == min(deviance))

optimal.ssnet.iar.a05.smallB <- ssnet.iar.smry.smallB %>%
  ungroup() %>%
  filter(alpha == 0.5) %>%
  filter(deviance == min(deviance))

optimal.ssnet.a1.smallB <- ssnet.smry.smallB %>% 
  ungroup() %>%
  filter(alpha == 1) %>%
  filter(deviance == min(deviance))

optimal.ssnet.iar.a1.smallB <- ssnet.iar.smry.smallB %>%
  ungroup() %>%
  filter(alpha == 1) %>%
  filter(deviance == min(deviance))

optimal.glmnet.smallB <- glmnet.smry.smallB %>%
  ungroup()

results.df.smallB <- rbind(optimal.glmnet.smallB %>% filter(alpha == 1),
                           optimal.ssnet.a1.smallB,
                           optimal.ssnet.iar.a1.smallB,
                           optimal.glmnet.smallB %>% filter(alpha == 0.5),
                           optimal.ssnet.a05.smallB,
                           optimal.ssnet.iar.a05.smallB)
```

## Tables

```{r}
knitr::kable(cbind(model = c("Lasso", "SSL", "SSL-IAR",
                             "EN", "SSEN", "SSEN-IAR"), 
                   results.df.smallB %>% 
                     select(s0, s1, deviance, auc, mse, mae, misclassification)),
             caption = "Prediction Error over 2,500 Simulated Data Sets",
             digits = 4)

knitr::kable(cbind(model = c("Lasso", "SSL", "SSL-IAR",
                             "EN", "SSEN", "SSEN-IAR"), 
                   results.df.smallB %>% 
                     select(s0, s1, accuracy, sensitivity, specificity, ppv, npv, mcc, f1)),
             caption = "Results over 2,500 Simulated Data Sets",
             digits = 4)

#for LaTeX
# xtable::xtable(cbind(model = c("Lasso", "SSL", "SSL-IAR",
#                              "EN", "SSEN", "SSEN-IAR"),
#                    results.df.smallB %>%
#                      select(s0, s1, deviance, auc, mse, mae, misclassification)),
#                digits = 4)
# xtable::xtable(cbind(model = c("Lasso", "SSL", "SSL-IAR",
#                              "EN", "SSEN", "SSEN-IAR"),
#                    results.df.smallB %>%
#                      select(s0, s1, accuracy, sensitivity, specificity, ppv, npv, mcc, f1)),
#                digits = 4)
```

## Figure

```{r}
# wrangle for figures
accuracy.wide.smallB <- cbind(Model = c("Lasso", "SSL", "SSL-IAR",
                             "EN", "SSEN", "SSEN-IAR"),
                       results.df.smallB %>% select(accuracy, sensitivity, specificity,
                                             ppv, npv, mcc, f1)
)

# number of models in total
nm <- 6
all.long.smallB <- cbind(accuracy.wide.smallB %>% select(Model),
                  Estimate = c(accuracy.wide.smallB$accuracy, 
                               accuracy.wide.smallB$sensitivity,
                               accuracy.wide.smallB$specificity,
                               accuracy.wide.smallB$ppv,
                               accuracy.wide.smallB$npv,
                               accuracy.wide.smallB$mcc,
                               accuracy.wide.smallB$f1),
                  Assessment = c(rep("Accuracy", nm),
                                 rep("Sensitivity", nm),
                                 rep("Specificity", nm),
                                 rep("PPV", nm),
                                 rep("NPV", nm),
                                 rep("MCC", nm),
                                 rep("F1", nm)))
names(all.long.smallB) <- c("Model", "Estimate", "Assessment")
all.long.smallB$Model <- factor(all.long.smallB$Model, 
                         levels = c("Lasso", "SSL", "SSL-IAR",
                                    "EN", "SSEN", "SSEN-IAR"))
all.long.smallB$Assessment <- factor(all.long.smallB$Assessment,
                              levels = c("Accuracy", "Sensitivity", "Specificity",
                                         "PPV", "NPV", "MCC", "F1"))

ggplot(data = all.long.smallB %>% 
         filter(Assessment %in% c("Sensitivity", "Specificity", "PPV", "NPV")),
       mapping = aes(y = Estimate,
                     x = Model, 
                     colour = Assessment,
                     shape = Assessment
                     )
       ) +
  geom_point(size = 3, stroke = 1.5,
             position = position_dodge(width = 0.75)) +
  scale_shape_manual(values = c(15, 17, 18, 25)) +
  scale_color_manual(values = cbpb[c(2, 4, 7, 6)]) +
  # scale_fill_manual(values = cbp.b[c(1, 2, 4, 7, 3 )]) +
  # facet_wrap(~Assessment) +
  scale_x_discrete(name = NULL) +
  scale_y_continuous(limits = c(0.2, 1),
                     breaks = seq(0.2, 1, 0.1)) +
  theme(plot.title = element_text(hjust = 0.5), 
        text = element_text(size = 14),
        legend.position = "bottom")

ggplot(data = all.long.smallB %>% 
         filter(Assessment %in% c("Accuracy", "MCC", "F1")),
       mapping = aes(y = Estimate,
                     x = Model, 
                     colour = Assessment,
                     shape = Assessment
                     )
       ) +
  geom_point(size = 3, stroke = 1.5,
             position = position_dodge(width = 0.75)) +
  scale_shape_manual(values = c(8, 4, 14)) +
  scale_color_manual(values = cbpb[c(1, 8, 3)]) +
  # scale_fill_manual(values = cbp.b[c(1, 2, 4, 7, 3 )]) +
  # facet_wrap(~Assessment) +
  scale_x_discrete(name = NULL) +
  scale_y_continuous(limits = c(0.3, 1),
                     breaks = seq(0.3, 1, 0.1)) +
  theme(plot.title = element_text(hjust = 0.5), 
        text = element_text(size = 14),
        legend.position = "bottom")

ggplot(data = all.long.smallB,
       mapping = aes(y = Estimate,
                     x = Model, 
                     colour = Assessment,
                     shape = Assessment
                     )
       ) +
  geom_point(size = 3, stroke = 1.5
             #,
             #position = position_dodge(width = 0.75)
             ) +
  scale_shape_manual(values = c(8, 15, 17, 18, 25, 4, 14)) +
  scale_color_manual(values = cbpb[c(8, 2, 4, 7, 6, 1, 3)]) +
  # scale_fill_manual(values = cbp.b[c(1, 2, 4, 7, 3 )]) +
  # facet_wrap(~Assessment) +
  scale_x_discrete(name = NULL) +
  scale_y_continuous(limits = c(0.2, 1),
                     breaks = seq(0.2, 1, 0.1)) +
  theme(plot.title = element_text(hjust = 0.5), 
        text = element_text(size = 14),
        legend.position = "bottom")
```

# Figure (both)

```{r}
all.long2 <- all.long %>%
  mutate(beta = 0.10)

all.long2.smallB <- all.long.smallB %>%
  mutate(beta = 0.05)

all2 <- bind_rows(all.long2,
                  all.long2.smallB)
```

```{r}
ggplot(data = all2,
       mapping = aes(y = Estimate,
                     x = Model, 
                     colour = Assessment,
                     shape = Assessment
                     )
       ) +
  facet_wrap(~beta,
             labeller = label_bquote(cols = beta == .(beta))) +
  geom_point(size = 3, stroke = 1.5
             #,
             #position = position_dodge(width = 0.75)
             ) +
  scale_shape_manual(values = c(8, 15, 17, 18, 25, 4, 14)) +
  scale_color_manual(values = cbpb[c(8, 2, 4, 7, 6, 1, 3)]) +
  # scale_fill_manual(values = cbp.b[c(1, 2, 4, 7, 3 )]) +
  # facet_wrap(~Assessment) +
  scale_x_discrete(name = NULL) +
  scale_y_continuous(limits = c(0.2, 1),
                     breaks = seq(0.2, 1, 0.1)) +
  theme(plot.title = element_text(hjust = 0.5), 
        text = element_text(size = 14),
        legend.position = "bottom")
```

# Variation of metrics 

It is good practice to look at the variability in reported metrics over the 2,500 simulations. We produce tables of SD's histograms for all metrics reported in the paper.

## Table of SD for $\beta_j = 0.1$

```{r}
glmnet.sds <- glmnet.smry.0 %>%
  select(-data, -means) %>%
  unnest(sds) %>% 
  mutate(model = "glmnet")

ssnet.sds <- ssnet.smry.0 %>%
  select(-data, -means) %>%
  unnest(sds) %>%
  mutate(model = "ssnet")

ssnet.iar.sds <- ssnet.iar.smry.0 %>%
  select(-data, -means) %>%
  unnest(sds) %>%
  mutate(model = "ssnet-iar")

sds.01 <- rbind(glmnet.sds,
                ssnet.sds,
                ssnet.iar.sds) %>%
  select(model, alpha, s0, s1, auc, mse, misclassification, accuracy, sensitivity, specificity, mcc, f1)

knitr::kable(sds.01,
             col.names = c("Model", "alpha", "s0", "s1",
                           "AUC", "MSE", "MC", "AC", "SN", "SP", "MCC", "F1"),
             caption = "SD for model fits over 2,500 simulations (beta = 0.10)",
             digits = 4)
```

## Table of SD for $\beta_j = 0.05$

```{r}
glmnet.sds.smallB <- glmnet.smry.smallB.0 %>%
  select(-data, -means) %>%
  unnest(sds) %>% 
  mutate(model = "glmnet")

ssnet.sds.smallB <- ssnet.smry.smallB.0 %>%
  select(-data, -means) %>%
  unnest(sds) %>%
  mutate(model = "ssnet")

ssnet.iar.sds.smallB <- ssnet.iar.smry.smallB.0 %>%
  select(-data, -means) %>%
  unnest(sds) %>%
  mutate(model = "ssnet-iar")

sds.01.smallB <- rbind(
  glmnet.sds.smallB,
  ssnet.sds.smallB,
  ssnet.iar.sds.smallB) %>%
  select(
    model, alpha, s0, s1, auc, mse, misclassification,
    accuracy, sensitivity, specificity, mcc, f1)

knitr::kable(sds.01.smallB,
             col.names = c("Model", "alpha", "s0", "s1",
                           "AUC", "MSE", "MC", "AC", "SN", "SP", "MCC", "F1"),
             caption = "SD for model fits over 2,500 simulations (0.05)",
             digits = 4)
```

## Figures

There are really too many combinations of parameters to display all plots. We present plots of the distributions of reported model fitness statistics based on the final models chosen for each case. 

### Parameter size 0.1

```{r}
glmnet.results.a1.opt <- glmnet.results %>%
  filter(alpha == 1)
glmnet.results.a05.opt <- glmnet.results %>%
  filter(alpha == 0.5)

ssnet.results$s0 <- round(ssnet.results$s0, digits = 2)
ssnet.results.a1.opt <- ssnet.results %>%
  filter(alpha == 1, s0 == 0.08, s1 == 1)
ssnet.results.a05.opt <- ssnet.results %>%
  filter(alpha == 0.5, s0 == 0.07, s1 == 1)

ssnet.iar.results$s0 <- round(ssnet.iar.results$s0, digits = 2)
ssnet.iar.results.a1.opt <- ssnet.iar.results %>%
  filter(alpha == 1, s0 == 0.10, s1 == 1)
ssnet.iar.results.a05.opt <- ssnet.iar.results %>%
  filter(alpha == 0.5, s0 == 0.10, s1 == 2)

results.opt <- bind_rows(
  glmnet.results.a1.opt,
  ssnet.results.a1.opt,
  ssnet.iar.results.a1.opt,
  glmnet.results.a05.opt,
  ssnet.results.a05.opt,
  ssnet.iar.results.a05.opt
)
```

```{r}
ggplot(data = results.opt,
       aes(x = auc)) +
  facet_wrap(alpha~model) +
  geom_histogram(fill = cbpg[8], color = cbpg[6]) +
  scale_y_continuous(name = "Frequency") +
  scale_x_continuous(name = "AUC") +
  ggtitle(bquote(paste("Distribution(s) of AUC for ", beta[j] == 0.1))) +
  theme(plot.title = element_text(hjust = 0.5), 
        text = element_text(size = 14),
        legend.position = "bottom")

ggplot(data = results.opt,
       aes(x = mse)) +
  facet_wrap(alpha~model) +
  geom_histogram(fill = cbpg[8], color = cbpg[6]) +
  scale_y_continuous(name = "Frequency") +
  scale_x_continuous(name = "MSE") +
  ggtitle(bquote(paste("Distribution(s) of MSE for ", beta[j] == 0.1))) +
  theme(plot.title = element_text(hjust = 0.5), 
        text = element_text(size = 14),
        legend.position = "bottom")

ggplot(data = results.opt,
       aes(x = accuracy)) +
  facet_wrap(alpha~model) +
  geom_histogram(fill = cbpg[8], color = cbpg[6]) +
  scale_y_continuous(name = "Frequency") +
  scale_x_continuous(name = "Accuracy") +
  ggtitle(bquote(paste("Distribution(s) of Accuracy for ", beta[j] == 0.1))) +
  theme(plot.title = element_text(hjust = 0.5), 
        text = element_text(size = 14),
        legend.position = "bottom")

ggplot(data = results.opt,
       aes(x = sensitivity)) +
  facet_wrap(alpha~model) +
  geom_histogram(fill = cbpg[8], color = cbpg[6]) +
  scale_y_continuous(name = "Frequency") +
  scale_x_continuous(name = "Sensitivity") +
  ggtitle(bquote(paste("Distribution(s) of Sensitivity for ", beta[j] == 0.1))) +
  theme(plot.title = element_text(hjust = 0.5), 
        text = element_text(size = 14),
        legend.position = "bottom")

ggplot(data = results.opt,
       aes(x = specificity)) +
  facet_wrap(alpha~model) +
  geom_histogram(fill = cbpg[8], color = cbpg[6]) +
  scale_y_continuous(name = "Frequency") +
  scale_x_continuous(name = "Specificity") +
  ggtitle(bquote(paste("Distribution(s) of Specificity for ", beta[j] == 0.1))) +
  theme(plot.title = element_text(hjust = 0.5), 
        text = element_text(size = 14),
        legend.position = "bottom")

ggplot(data = results.opt,
       aes(x = ppv)) +
  facet_wrap(alpha~model) +
  geom_histogram(fill = cbpg[8], color = cbpg[6]) +
  scale_y_continuous(name = "Frequency") +
  scale_x_continuous(name = "PPV") +
  ggtitle(bquote(paste("Distribution(s) of PPV for ", beta[j] == 0.1))) +
  theme(plot.title = element_text(hjust = 0.5), 
        text = element_text(size = 14),
        legend.position = "bottom")

ggplot(data = results.opt,
       aes(x = npv)) +
  facet_wrap(alpha~model) +
  geom_histogram(fill = cbpg[8], color = cbpg[6]) +
  scale_y_continuous(name = "Frequency") +
  scale_x_continuous(name = "NPV") +
  ggtitle(bquote(paste("Distribution(s) of NPV for ", beta[j] == 0.1))) +
  theme(plot.title = element_text(hjust = 0.5), 
        text = element_text(size = 14),
        legend.position = "bottom")

ggplot(data = results.opt,
       aes(x = mcc)) +
  facet_wrap(alpha~model) +
  geom_histogram(fill = cbpg[8], color = cbpg[6]) +
  scale_y_continuous(name = "Frequency") +
  scale_x_continuous(name = "MCC") +
  ggtitle(bquote(paste("Distribution(s) of MCC for ", beta[j] == 0.1))) +
  theme(plot.title = element_text(hjust = 0.5), 
        text = element_text(size = 14),
        legend.position = "bottom")

ggplot(data = results.opt,
       aes(x = f1)) +
  facet_wrap(alpha~model) +
  geom_histogram(fill = cbpg[8], color = cbpg[6]) +
  scale_y_continuous(name = "Frequency") +
  scale_x_continuous(name = "F1") +
  ggtitle(bquote(paste("Distribution(s) of F1 for ", beta[j] == 0.1))) +
  theme(plot.title = element_text(hjust = 0.5), 
        text = element_text(size = 14),
        legend.position = "bottom")

```

### Parameter size 0.05

```{r}
glmnet.results.smallB.a1.opt <- glmnet.results.smallB %>%
  filter(alpha == 1)
glmnet.results.smallB.a05.opt <- glmnet.results.smallB %>%
  filter(alpha == 0.5)

ssnet.results.smallB$s0 <- round(ssnet.results.smallB$s0, digits = 2)
ssnet.results.smallB.a1.opt <- ssnet.results.smallB %>%
  filter(alpha == 1, s0 == 0.06, s1 == 1)
ssnet.results.smallB.a05.opt <- ssnet.results.smallB %>%
  filter(alpha == 0.5, s0 == 0.09, s1 == 1)

ssnet.iar.results.smallB$s0 <- round(ssnet.iar.results.smallB$s0, digits = 2)
ssnet.iar.results.smallB.a1.opt <- ssnet.iar.results.smallB %>%
  filter(alpha == 1, s0 == 0.05, s1 == 1)
ssnet.iar.results.smallB.a05.opt <- ssnet.iar.results.smallB %>%
  filter(alpha == 0.5, s0 == 0.10, s1 == 2)

results.smallB.opt <- bind_rows(
  glmnet.results.smallB.a1.opt,
  ssnet.results.smallB.a1.opt,
  ssnet.iar.results.smallB.a1.opt,
  glmnet.results.smallB.a05.opt,
  ssnet.results.smallB.a05.opt,
  ssnet.iar.results.smallB.a05.opt
)
```

```{r}
ggplot(data = results.smallB.opt,
       aes(x = auc)) +
  facet_wrap(alpha~model) +
  geom_histogram(fill = cbpg[8], color = cbpg[6]) +
  scale_y_continuous(name = "Frequency") +
  scale_x_continuous(name = "AUC") +
  ggtitle(bquote(paste("Distribution(s) of AUC for ", beta[j] == 0.05))) +
  theme(plot.title = element_text(hjust = 0.5), 
        text = element_text(size = 14),
        legend.position = "bottom")

ggplot(data = results.smallB.opt,
       aes(x = mse)) +
  facet_wrap(alpha~model) +
  geom_histogram(fill = cbpg[8], color = cbpg[6]) +
  scale_y_continuous(name = "Frequency") +
  scale_x_continuous(name = "MSE") +
  ggtitle(bquote(paste("Distribution(s) of MSE for ", beta[j] == 0.05))) +
  theme(plot.title = element_text(hjust = 0.5), 
        text = element_text(size = 14),
        legend.position = "bottom")

ggplot(data = results.smallB.opt,
       aes(x = accuracy)) +
  facet_wrap(alpha~model) +
  geom_histogram(fill = cbpg[8], color = cbpg[6]) +
  scale_y_continuous(name = "Frequency") +
  scale_x_continuous(name = "Accuracy") +
  ggtitle(bquote(paste("Distribution(s) of Accuracy for ", beta[j] == 0.05))) +
  theme(plot.title = element_text(hjust = 0.5), 
        text = element_text(size = 14),
        legend.position = "bottom")

ggplot(data = results.smallB.opt,
       aes(x = sensitivity)) +
  facet_wrap(alpha~model) +
  geom_histogram(fill = cbpg[8], color = cbpg[6]) +
  scale_y_continuous(name = "Frequency") +
  scale_x_continuous(name = "Sensitivity") +
  ggtitle(bquote(paste("Distribution(s) of Sensitivity for ", beta[j] == 0.05))) +
  theme(plot.title = element_text(hjust = 0.5), 
        text = element_text(size = 14),
        legend.position = "bottom")

ggplot(data = results.smallB.opt,
       aes(x = specificity)) +
  facet_wrap(alpha~model) +
  geom_histogram(fill = cbpg[8], color = cbpg[6]) +
  scale_y_continuous(name = "Frequency") +
  scale_x_continuous(name = "Specificity") +
  ggtitle(bquote(paste("Distribution(s) of Specificity for ", beta[j] == 0.05))) +
  theme(plot.title = element_text(hjust = 0.5), 
        text = element_text(size = 14),
        legend.position = "bottom")

ggplot(data = results.smallB.opt,
       aes(x = ppv)) +
  facet_wrap(alpha~model) +
  geom_histogram(fill = cbpg[8], color = cbpg[6]) +
  scale_y_continuous(name = "Frequency") +
  scale_x_continuous(name = "PPV") +
  ggtitle(bquote(paste("Distribution(s) of PPV for ", beta[j] == 0.05))) +
  theme(plot.title = element_text(hjust = 0.5), 
        text = element_text(size = 14),
        legend.position = "bottom")

ggplot(data = results.smallB.opt,
       aes(x = npv)) +
  facet_wrap(alpha~model) +
  geom_histogram(fill = cbpg[8], color = cbpg[6]) +
  scale_y_continuous(name = "Frequency") +
  scale_x_continuous(name = "NPV") +
  ggtitle(bquote(paste("Distribution(s) of NPV for ", beta[j] == 0.05))) +
  theme(plot.title = element_text(hjust = 0.5), 
        text = element_text(size = 14),
        legend.position = "bottom")

ggplot(data = results.smallB.opt,
       aes(x = mcc)) +
  facet_wrap(alpha~model) +
  geom_histogram(fill = cbpg[8], color = cbpg[6]) +
  scale_y_continuous(name = "Frequency") +
  scale_x_continuous(name = "MCC") +
  ggtitle(bquote(paste("Distribution(s) of MCC for ", beta[j] == 0.05))) +
  theme(plot.title = element_text(hjust = 0.5), 
        text = element_text(size = 14),
        legend.position = "bottom")

ggplot(data = results.smallB.opt,
       aes(x = f1)) +
  facet_wrap(alpha~model) +
  geom_histogram(fill = cbpg[8], color = cbpg[6]) +
  scale_y_continuous(name = "Frequency") +
  scale_x_continuous(name = "F1") +
  ggtitle(bquote(paste("Distribution(s) of F1 for ", beta[j] == 0.05))) +
  theme(plot.title = element_text(hjust = 0.5), 
        text = element_text(size = 14),
        legend.position = "bottom")

```










